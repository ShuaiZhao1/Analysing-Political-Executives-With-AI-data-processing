{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963d0e0f",
   "metadata": {},
   "source": [
    "# Analysing Political Executives with AI\n",
    "\n",
    "## Using AutoGluon to processing the data\n",
    "\n",
    "\n",
    "```shell\n",
    "# Link for how to install autogluon on Windows system\n",
    "# https://auto.gluon.ai/stable/index.html\n",
    "# For other operation systems, please also check this link for latest news. \n",
    "\n",
    "# test automl model\n",
    "# install autogluon\n",
    "!pip3 install -U pip\n",
    "!pip3 install -U setuptools wheel\n",
    "\n",
    "# CPU version of pytorch has smaller footprint - see installation instructions in\n",
    "# pytorch documentation - https://pytorch.org/get-started/locally/\n",
    "!pip3 install torch==1.10.1+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "\n",
    "!pip3 install autogluon\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba2fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split #splitting the dataset\n",
    "import numpy as np\n",
    "\n",
    "# Showing all the details of results\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42720e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data file\n",
    "train_data = TabularDataset('data_AutoGluon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d2195d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autogluon.core.dataset.TabularDataset"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['ccode', 'leader', 'entry', 'exit', 'exitcode', 'prevtimesinoffice',\n",
       "       'posttenurefate', 'gender', 'yrborn', 'yrdied', 'numentry', 'numexit',\n",
       "       'yrbegin', 'yrend', 'pop_x', 'begin_gdppc', 'pop_y', 'age', 'tenure',\n",
       "       'growth_rate', 'fties_range', 'growth_rate_normgroup',\n",
       "       'growth_rate_avggrp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccode</th>\n",
       "      <th>leader</th>\n",
       "      <th>entry</th>\n",
       "      <th>exit</th>\n",
       "      <th>exitcode</th>\n",
       "      <th>prevtimesinoffice</th>\n",
       "      <th>posttenurefate</th>\n",
       "      <th>gender</th>\n",
       "      <th>yrborn</th>\n",
       "      <th>yrdied</th>\n",
       "      <th>...</th>\n",
       "      <th>yrend</th>\n",
       "      <th>pop_x</th>\n",
       "      <th>begin_gdppc</th>\n",
       "      <th>pop_y</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>fties_range</th>\n",
       "      <th>growth_rate_normgroup</th>\n",
       "      <th>growth_rate_avggrp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Grant</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.069364</td>\n",
       "      <td>0.954122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.034455</td>\n",
       "      <td>0.029689</td>\n",
       "      <td>0.029199</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.142921</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Hayes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.069364</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.037693</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.035105</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.061228</td>\n",
       "      <td>0.059757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.109827</td>\n",
       "      <td>0.954480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>0.038625</td>\n",
       "      <td>0.038392</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.156069</td>\n",
       "      <td>0.962366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093525</td>\n",
       "      <td>0.045222</td>\n",
       "      <td>0.039319</td>\n",
       "      <td>0.042213</td>\n",
       "      <td>0.449275</td>\n",
       "      <td>0.061228</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.132948</td>\n",
       "      <td>0.959857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122302</td>\n",
       "      <td>0.049044</td>\n",
       "      <td>0.041150</td>\n",
       "      <td>0.046034</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.061228</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ccode     leader  entry  exit  exitcode  prevtimesinoffice  posttenurefate  \\\n",
       "0    0.0      Grant    0.0   0.0  0.285714                0.0           0.625   \n",
       "1    0.0      Hayes    0.0   0.0  0.285714                0.0           0.625   \n",
       "2    0.0     Arthur    0.0   0.0  0.285714                0.0           0.625   \n",
       "3    0.0  Cleveland    0.0   0.0  0.285714                0.0           0.625   \n",
       "4    0.0   Harrison    0.0   0.0  0.285714                0.0           0.625   \n",
       "\n",
       "   gender    yrborn    yrdied  ...     yrend     pop_x  begin_gdppc     pop_y  \\\n",
       "0     0.5  0.069364  0.954122  ...  0.007194  0.034455     0.029689  0.029199   \n",
       "1     0.5  0.069364  0.956989  ...  0.035971  0.037693     0.030700  0.035105   \n",
       "2     0.5  0.109827  0.954480  ...  0.064748  0.041457     0.038625  0.038392   \n",
       "3     0.5  0.156069  0.962366  ...  0.093525  0.045222     0.039319  0.042213   \n",
       "4     0.5  0.132948  0.959857  ...  0.122302  0.049044     0.041150  0.046034   \n",
       "\n",
       "        age    tenure  growth_rate  fties_range  growth_rate_normgroup  \\\n",
       "0  0.434783  0.142921     0.003934          1.0                      4   \n",
       "1  0.550725  0.061228     0.059757          1.0                      4   \n",
       "2  0.507246  0.050101     0.004888          1.0                      4   \n",
       "3  0.449275  0.061228     0.010956          1.0                      4   \n",
       "4  0.565217  0.061228     0.004793          1.0                      4   \n",
       "\n",
       "   growth_rate_avggrp  \n",
       "0                   5  \n",
       "1                   4  \n",
       "2                   5  \n",
       "3                   5  \n",
       "4                   5  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccode</th>\n",
       "      <th>entry</th>\n",
       "      <th>exit</th>\n",
       "      <th>exitcode</th>\n",
       "      <th>prevtimesinoffice</th>\n",
       "      <th>posttenurefate</th>\n",
       "      <th>gender</th>\n",
       "      <th>yrborn</th>\n",
       "      <th>yrdied</th>\n",
       "      <th>numentry</th>\n",
       "      <th>...</th>\n",
       "      <th>yrend</th>\n",
       "      <th>pop_x</th>\n",
       "      <th>begin_gdppc</th>\n",
       "      <th>pop_y</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>fties_range</th>\n",
       "      <th>growth_rate_normgroup</th>\n",
       "      <th>growth_rate_avggrp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>899.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.0</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>922.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.390935</td>\n",
       "      <td>0.079718</td>\n",
       "      <td>0.151302</td>\n",
       "      <td>0.372017</td>\n",
       "      <td>0.062093</td>\n",
       "      <td>0.496475</td>\n",
       "      <td>0.511388</td>\n",
       "      <td>0.553885</td>\n",
       "      <td>0.652212</td>\n",
       "      <td>0.079718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643300</td>\n",
       "      <td>0.031253</td>\n",
       "      <td>0.052354</td>\n",
       "      <td>0.029527</td>\n",
       "      <td>0.541718</td>\n",
       "      <td>0.086704</td>\n",
       "      <td>0.020790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.924078</td>\n",
       "      <td>4.815618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.289082</td>\n",
       "      <td>0.197406</td>\n",
       "      <td>0.283199</td>\n",
       "      <td>0.214789</td>\n",
       "      <td>0.146002</td>\n",
       "      <td>0.263134</td>\n",
       "      <td>0.074636</td>\n",
       "      <td>0.224373</td>\n",
       "      <td>0.463421</td>\n",
       "      <td>0.197406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277630</td>\n",
       "      <td>0.097848</td>\n",
       "      <td>0.069842</td>\n",
       "      <td>0.091977</td>\n",
       "      <td>0.151286</td>\n",
       "      <td>0.111121</td>\n",
       "      <td>0.047728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504793</td>\n",
       "      <td>0.500440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.320763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.158025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.381503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424460</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.012873</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.021276</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.374074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.595376</td>\n",
       "      <td>0.970968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.028166</td>\n",
       "      <td>0.006395</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.061088</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.553086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.987097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884892</td>\n",
       "      <td>0.026059</td>\n",
       "      <td>0.061935</td>\n",
       "      <td>0.024348</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.102047</td>\n",
       "      <td>0.039507</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.532870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ccode       entry        exit    exitcode  prevtimesinoffice  \\\n",
       "count  922.000000  922.000000  922.000000  922.000000         922.000000   \n",
       "mean     0.390935    0.079718    0.151302    0.372017           0.062093   \n",
       "std      0.289082    0.197406    0.283199    0.214789           0.146002   \n",
       "min      0.000000    0.000000    0.000000    0.000000           0.000000   \n",
       "25%      0.158025    0.000000    0.000000    0.285714           0.000000   \n",
       "50%      0.374074    0.000000    0.000000    0.285714           0.000000   \n",
       "75%      0.553086    0.000000    0.166667    0.285714           0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000           1.000000   \n",
       "\n",
       "       posttenurefate      gender      yrborn      yrdied    numentry  ...  \\\n",
       "count      922.000000  922.000000  922.000000  922.000000  922.000000  ...   \n",
       "mean         0.496475    0.511388    0.553885    0.652212    0.079718  ...   \n",
       "std          0.263134    0.074636    0.224373    0.463421    0.197406  ...   \n",
       "min          0.000000    0.500000    0.000000    0.000000    0.000000  ...   \n",
       "25%          0.250000    0.500000    0.381503    0.000000    0.000000  ...   \n",
       "50%          0.625000    0.500000    0.595376    0.970968    0.000000  ...   \n",
       "75%          0.625000    0.500000    0.734104    0.987097    0.000000  ...   \n",
       "max          1.000000    1.000000    1.000000    1.000000    1.000000  ...   \n",
       "\n",
       "            yrend       pop_x  begin_gdppc       pop_y         age  \\\n",
       "count  922.000000  902.000000   922.000000  899.000000  922.000000   \n",
       "mean     0.643300    0.031253     0.052354    0.029527    0.541718   \n",
       "std      0.277630    0.097848     0.069842    0.091977    0.151286   \n",
       "min      0.000000    0.000000     0.000000    0.000000    0.000000   \n",
       "25%      0.424460    0.002552     0.012873    0.002473    0.434783   \n",
       "50%      0.690647    0.006850     0.028166    0.006395    0.536232   \n",
       "75%      0.884892    0.026059     0.061935    0.024348    0.637681   \n",
       "max      1.000000    1.000000     1.000000    1.000000    1.000000   \n",
       "\n",
       "           tenure  growth_rate  fties_range  growth_rate_normgroup  \\\n",
       "count  922.000000   922.000000        922.0             922.000000   \n",
       "mean     0.086704     0.020790          1.0               3.924078   \n",
       "std      0.111121     0.047728          0.0               0.504793   \n",
       "min      0.000000    -0.320763          1.0               1.000000   \n",
       "25%      0.021276     0.003340          1.0               4.000000   \n",
       "50%      0.061088     0.019832          1.0               4.000000   \n",
       "75%      0.102047     0.039507          1.0               4.000000   \n",
       "max      1.000000     0.532870          1.0               7.000000   \n",
       "\n",
       "       growth_rate_avggrp  \n",
       "count          922.000000  \n",
       "mean             4.815618  \n",
       "std              0.500440  \n",
       "min              1.000000  \n",
       "25%              5.000000  \n",
       "50%              5.000000  \n",
       "75%              5.000000  \n",
       "max              7.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)\n",
    "\n",
    "train_data.columns\n",
    "\n",
    "train_data.head()\n",
    "\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db082bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ccode', 'leader', 'entry', 'exit', 'exitcode', 'prevtimesinoffice',\n",
       "       'posttenurefate', 'gender', 'yrborn', 'yrdied', 'numentry', 'numexit',\n",
       "       'yrbegin', 'yrend', 'pop_x', 'begin_gdppc', 'pop_y', 'age', 'tenure',\n",
       "       'fties_range', 'growth_rate_avggrp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete other irrelevant columns\n",
    "del train_data['growth_rate_normgroup']\n",
    "# del train_data['growth_rate_avggrp']\n",
    "del train_data['growth_rate']\n",
    "train_data.columns\n",
    "\n",
    "# change label into growth_rate\n",
    "# id, label = 'leader', 'growth_rate'\n",
    "\n",
    "# change label into growth_rate_normgroup\n",
    "# id, label = 'leader', 'growth_rate_normgroup'\n",
    "\n",
    "# change label into growth_rate group\n",
    "id, label = 'leader', 'growth_rate_avggrp'\n",
    "df_train = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd63514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ccode                 float64\n",
       "leader                 object\n",
       "entry                 float64\n",
       "exit                  float64\n",
       "exitcode              float64\n",
       "prevtimesinoffice     float64\n",
       "posttenurefate        float64\n",
       "gender                float64\n",
       "yrborn                float64\n",
       "yrdied                float64\n",
       "numentry              float64\n",
       "numexit               float64\n",
       "yrbegin               float64\n",
       "yrend                 float64\n",
       "pop_x                 float64\n",
       "begin_gdppc           float64\n",
       "pop_y                 float64\n",
       "age                   float64\n",
       "tenure                float64\n",
       "fties_range           float64\n",
       "growth_rate_avggrp      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "768e3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train data and test data\n",
    "# df_train, df_test=train_test_split(train_data, test_size=0.33, random_state=1)\n",
    "# df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d646a5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220502_082101\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220502_082101\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    922\n",
      "Train Data Columns: 19\n",
      "Label Column: growth_rate_avggrp\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t7 unique label values:  [5, 4, 6, 3, 7, 1, 2]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 7 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9869848156182213\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8854.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.14 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['fties_range']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 18 | ['ccode', 'entry', 'exit', 'exitcode', 'prevtimesinoffice', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 17 | ['ccode', 'entry', 'exit', 'exitcode', 'prevtimesinoffice', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['gender']\n",
      "\t0.0s = Fit runtime\n",
      "\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.12 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 728, Val Rows: 182\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.7418\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7473\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7912\t = Validation score   (accuracy)\n",
      "\t1.97s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.7967\t = Validation score   (accuracy)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.7967\t = Validation score   (accuracy)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8022\t = Validation score   (accuracy)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8022\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8022\t = Validation score   (accuracy)\n",
      "\t1.67s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7857\t = Validation score   (accuracy)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7912\t = Validation score   (accuracy)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7912\t = Validation score   (accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7857\t = Validation score   (accuracy)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.7967\t = Validation score   (accuracy)\n",
      "\t1.52s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8022\t = Validation score   (accuracy)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.17s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220502_082101\\\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(\n",
    "    df_train.drop(columns=[id, 'leader']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e89213f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.947939</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.080998</td>\n",
       "      <td>0.044998</td>\n",
       "      <td>0.486002</td>\n",
       "      <td>0.080998</td>\n",
       "      <td>0.044998</td>\n",
       "      <td>0.486002</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.947939</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.088998</td>\n",
       "      <td>0.044998</td>\n",
       "      <td>0.747029</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261026</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.947939</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.089002</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.406001</td>\n",
       "      <td>0.089002</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.406001</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.945770</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.088999</td>\n",
       "      <td>0.050999</td>\n",
       "      <td>0.385002</td>\n",
       "      <td>0.088999</td>\n",
       "      <td>0.050999</td>\n",
       "      <td>0.385002</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.944685</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.083997</td>\n",
       "      <td>0.050998</td>\n",
       "      <td>0.393002</td>\n",
       "      <td>0.083997</td>\n",
       "      <td>0.050998</td>\n",
       "      <td>0.393002</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.938178</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.518998</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.518998</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.937093</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.011002</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.011002</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.830803</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.835021</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.835021</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.811280</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.806941</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>1.673000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>1.673000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.804772</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.142998</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.142998</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.793926</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.968158</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.968158</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.781996</td>\n",
       "      <td>0.741758</td>\n",
       "      <td>0.021003</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.021003</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.773319</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0      RandomForestGini    0.947939   0.802198        0.080998       0.044998   \n",
       "1   WeightedEnsemble_L2    0.947939   0.802198        0.088998       0.044998   \n",
       "2      RandomForestEntr    0.947939   0.802198        0.089002       0.051999   \n",
       "3        ExtraTreesEntr    0.945770   0.791209        0.088999       0.050999   \n",
       "4        ExtraTreesGini    0.944685   0.785714        0.083997       0.050998   \n",
       "5         LightGBMLarge    0.938178   0.796703        0.009001       0.004000   \n",
       "6        KNeighborsDist    0.937093   0.747253        0.023000       0.011002   \n",
       "7               XGBoost    0.830803   0.791209        0.008002       0.006974   \n",
       "8              LightGBM    0.811280   0.796703        0.003997       0.005000   \n",
       "9              CatBoost    0.806941   0.802198        0.003000       0.001002   \n",
       "10           LightGBMXT    0.804772   0.796703        0.009999       0.005000   \n",
       "11      NeuralNetFastAI    0.793926   0.791209        0.027000       0.016000   \n",
       "12       KNeighborsUnif    0.781996   0.741758        0.021003       0.014000   \n",
       "13       NeuralNetTorch    0.773319   0.785714        0.024000       0.012000   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.486002                 0.080998                0.044998   \n",
       "1   0.747029                 0.008000                0.000000   \n",
       "2   0.406001                 0.089002                0.051999   \n",
       "3   0.385002                 0.088999                0.050999   \n",
       "4   0.393002                 0.083997                0.050998   \n",
       "5   1.518998                 0.009001                0.004000   \n",
       "6   0.005996                 0.023000                0.011002   \n",
       "7   0.835021                 0.008002                0.006974   \n",
       "8   0.684000                 0.003997                0.005000   \n",
       "9   1.673000                 0.003000                0.001002   \n",
       "10  1.142998                 0.009999                0.005000   \n",
       "11  1.968158                 0.027000                0.016000   \n",
       "12  0.007000                 0.021003                0.014000   \n",
       "13  1.350000                 0.024000                0.012000   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.486002            1       True          6  \n",
       "1            0.261026            2       True         14  \n",
       "2            0.406001            1       True          7  \n",
       "3            0.385002            1       True         10  \n",
       "4            0.393002            1       True          9  \n",
       "5            1.518998            1       True         13  \n",
       "6            0.005996            1       True          2  \n",
       "7            0.835021            1       True         11  \n",
       "8            0.684000            1       True          5  \n",
       "9            1.673000            1       True          8  \n",
       "10           1.142998            1       True          4  \n",
       "11           1.968158            1       True          3  \n",
       "12           0.007000            1       True          1  \n",
       "13           1.350000            1       True         12  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(df_train.drop(columns=[id, 'leader']), silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab18d4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['leader', 'fties_range']\n",
      "Computing feature importance via permutation shuffling for 18 features using 910 rows with 3 shuffle sets...\n",
      "\t5.47s\t= Expected runtime (1.82s per shuffle set)\n",
      "\t0.56s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>begin_gdppc</th>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>3</td>\n",
       "      <td>0.081293</td>\n",
       "      <td>0.026399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccode</th>\n",
       "      <td>0.036630</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>3</td>\n",
       "      <td>0.066388</td>\n",
       "      <td>0.006872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yrborn</th>\n",
       "      <td>0.028205</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>0.007502</td>\n",
       "      <td>3</td>\n",
       "      <td>0.062885</td>\n",
       "      <td>-0.006475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_x</th>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>3</td>\n",
       "      <td>0.049480</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>0.024542</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>3</td>\n",
       "      <td>0.048382</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yrdied</th>\n",
       "      <td>0.022711</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>3</td>\n",
       "      <td>0.044824</td>\n",
       "      <td>0.000597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yrbegin</th>\n",
       "      <td>0.021612</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>3</td>\n",
       "      <td>0.034720</td>\n",
       "      <td>0.008504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yrend</th>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040754</td>\n",
       "      <td>0.000271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.016484</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>3</td>\n",
       "      <td>0.029077</td>\n",
       "      <td>0.003890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_y</th>\n",
       "      <td>0.013187</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>3</td>\n",
       "      <td>0.032077</td>\n",
       "      <td>-0.005704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posttenurefate</th>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numexit</th>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>-0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exitcode</th>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.037090</td>\n",
       "      <td>3</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>-0.004099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exit</th>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.091752</td>\n",
       "      <td>3</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>-0.005806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.091752</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>-0.002903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numentry</th>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.091752</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>-0.002903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevtimesinoffice</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.211325</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>-0.003269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   importance    stddev   p_value  n  p99_high   p99_low\n",
       "begin_gdppc          0.053846  0.004790  0.001314  3  0.081293  0.026399\n",
       "ccode                0.036630  0.005193  0.003317  3  0.066388  0.006872\n",
       "yrborn               0.028205  0.006052  0.007502  3  0.062885 -0.006475\n",
       "pop_x                0.025641  0.004160  0.004331  3  0.049480  0.001802\n",
       "tenure               0.024542  0.004160  0.004722  3  0.048382  0.000703\n",
       "yrdied               0.022711  0.003859  0.004744  3  0.044824  0.000597\n",
       "yrbegin              0.021612  0.002288  0.001857  3  0.034720  0.008504\n",
       "yrend                0.020513  0.003532  0.004871  3  0.040754  0.000271\n",
       "age                  0.016484  0.002198  0.002937  3  0.029077  0.003890\n",
       "pop_y                0.013187  0.003297  0.010102  3  0.032077 -0.005704\n",
       "posttenurefate       0.004029  0.000634  0.004082  3  0.007665  0.000394\n",
       "numexit              0.002564  0.000634  0.009902  3  0.006200 -0.001071\n",
       "exitcode             0.002198  0.001099  0.037090  3  0.008495 -0.004099\n",
       "exit                 0.001465  0.001269  0.091752  3  0.008736 -0.005806\n",
       "entry                0.000733  0.000634  0.091752  3  0.004368 -0.002903\n",
       "numentry             0.000733  0.000634  0.091752  3  0.004368 -0.002903\n",
       "prevtimesinoffice    0.000366  0.000634  0.211325  3  0.004002 -0.003269\n",
       "gender               0.000000  0.000000  0.500000  3  0.000000  0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(df_train, subsample_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da9f6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.evaluate(df_test.drop(columns=[id, 'leader']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Importance')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.XTick at 0x1522d65e3d0>,\n",
       " <matplotlib.axis.XTick at 0x1522d65e3a0>,\n",
       " <matplotlib.axis.XTick at 0x1522d656040>,\n",
       " <matplotlib.axis.XTick at 0x1522aaacc40>,\n",
       " <matplotlib.axis.XTick at 0x1522aabd3d0>,\n",
       " <matplotlib.axis.XTick at 0x1522aabdb20>,\n",
       " <matplotlib.axis.XTick at 0x1522aabddf0>,\n",
       " <matplotlib.axis.XTick at 0x1522aaacd00>,\n",
       " <matplotlib.axis.XTick at 0x1522aac47c0>,\n",
       " <matplotlib.axis.XTick at 0x1522aad0070>,\n",
       " <matplotlib.axis.XTick at 0x1522aad06a0>,\n",
       " <matplotlib.axis.XTick at 0x1522aad0df0>,\n",
       " <matplotlib.axis.XTick at 0x1522aad6580>,\n",
       " <matplotlib.axis.XTick at 0x1522aad0a90>,\n",
       " <matplotlib.axis.XTick at 0x1522aac47f0>,\n",
       " <matplotlib.axis.XTick at 0x1522aad60d0>,\n",
       " <matplotlib.axis.XTick at 0x1522aade220>,\n",
       " <matplotlib.axis.XTick at 0x1522aade970>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1522d67c520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "labels = ['age', 'begin_gdppc', 'ccode', 'entry', 'exit', 'exitcode', 'gender', 'numentry',\n",
    "'numexit', 'pop_x', 'pop_y', 'posttenurefate', 'prevtimesinoffice', 'tenure', 'yrbegin', \n",
    "'yrborn', 'yrdied', 'yrend']\n",
    "Linear_Regression = ['0.007565', '0.005877', '0.012403', '0.006895', '0.003671', '0.004737', '0.000005', '0.005501', '0.001576', '0.00377', '0.003155', '0.004747', '0.002821', '0.009953', '0.010795', '0.009525', '0.008158', '0.010314']\n",
    "Norm_Classification = ['0.023179', '0.030905', '0.03532', '0.015085', '0.015453', '0.00184', '0', '0', '0.005151', '0.032745', '0.031641', '0.004783', '0.005151', '0.03716', '0.020603', '0.027226', '0.022811', '0.014717']\n",
    "Equivalent_Classification = ['0.016484', '0.053846', '0.03663', '0.000733', '0.001465', '0.002198', '0', '0.000733', '0.002564', '0.025641', '0.013187', '0.004029', '0.000366', '0.024542', '0.021612', '0.028205', '0.022711', '0.020513']\n",
    "\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.3  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, np.double(Linear_Regression), width, label='Linear Regression')\n",
    "rects2 = ax.bar(x, np.double(Norm_Classification), width, label='Norm Classification')\n",
    "rects2 = ax.bar(x + width/2, np.double(Equivalent_Classification), width, label='Equivalent Classification')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Importance')\n",
    "# ax.set_title('Importance')\n",
    "ax.set_xticks(x, labels, rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
